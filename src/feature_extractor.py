import torch
import torch.nn as nn
import torchvision.models as models
from torchvision import transforms
from torch.utils.data import DataLoader
import numpy as np
from tqdm import tqdm
from data_utils import BrainScanDataset


def extract_features(csv_path, output_path):
    """Extrait les caract√©ristiques d'images √† l'aide d'un mod√®le ResNet50 pr√©-entra√Æn√©.

    Cette fonction charge un ensemble de donn√©es d'images sp√©cifi√© par un fichier CSV,
    puis utilise un mod√®le ResNet50 (pr√©-entra√Æn√© sur ImageNet) pour extraire
    un vecteur de caract√©ristiques pour chaque image. La derni√®re couche du mod√®le
    est retir√©e pour obtenir le vecteur avant la classification.

    Les caract√©ristiques extraites sont ensuite sauvegard√©es dans un fichier .npy.

    Args:
        csv_path (str): Le chemin vers le fichier CSV contenant les m√©tadonn√©es
            des images (notamment le chemin de chaque image).
        output_path (str): Le chemin du fichier .npy de sortie o√π seront
            sauvegard√©es les caract√©ristiques extraites.
    
    Returns:
        None
    """
    # 1. Pipeline de transformation (Standard ImageNet)
    preprocess = transforms.Compose(
        [
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )

    # 2. Chargement du mod√®le ResNet50
    # On utilise les poids pr√©-entra√Æn√©s
    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)

    # On g√®le les param√®tres (pas d'entra√Ænement ici)
    for param in model.parameters():
        param.requires_grad = False

    # On remplace la derni√®re couche (classification) par une couche "Identit√©"
    # pour r√©cup√©rer le vecteur de 2048 dimensions
    model.fc = nn.Identity()  # type: ignore

    # Passage en mode √©valuation et sur GPU si disponible
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    model.eval()

    # 3. DataLoader
    dataset = BrainScanDataset(csv_path, transform=preprocess)
    loader = DataLoader(dataset, batch_size=32, shuffle=False)

    features = []

    # 4. Boucle d'extraction
    print(f"üöÄ Extraction des features sur {device}...")
    with torch.no_grad():
        for imgs, _ in tqdm(loader):
            imgs = imgs.to(device)
            embeddings = model(imgs)
            features.append(embeddings.cpu().numpy())

    # 5. Sauvegarde
    features_array = np.vstack(features)
    np.save(output_path, features_array)
    print(
        f"‚úÖ Termin√© ! Features sauvegard√©es dans {output_path} (Shape: {features_array.shape})"
    )


if __name__ == "__main__":
    extract_features("data/metadata.csv", "data/processed/features_resnet.npy")
